{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de Datos con python\n",
    "==============\n",
    "**Author:** *Jhoan Sebastian Almeida Caicedo*\n",
    "\n",
    "***07 de enero de 2020***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Un analista de datos es alguien que usa datos para responder preguntas**\n",
    "\n",
    "Para cada conjunto de datos, se tendra la oportunidad de plantear sus propias preguntas\n",
    "y realizar tus propias investigaciones\n",
    "\n",
    "Librerias como NumPy, Pandas y Matplotlib nos facilitan el analisis de los datos\n",
    "\n",
    "En la actualidad el analisis de datos es indispensable por ejemplo las compañias\n",
    "farmaceuticas han comenzado a utilizar el aprendizaje automatico para predecir que compuestos quimicos tiene mas probabilidades de producir\n",
    "medicamentos efectivos, usando esto, pueden tomar mejores decisiones sobre que compuestos es probable que sean un bien uso de los recursos involucrados en \n",
    "la ejecucion de un ensayo clinico.\n",
    "\n",
    "\n",
    "![Analista](https://www.bbva.com/wp-content/uploads/2016/07/bbva-perfil-analista-datos-1024x701.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proceso de analisis de datos (Fases).**\n",
    "\n",
    "1. Pregunta que se desea responder o un problema que se quiera resolver.\n",
    "2. Disputa de datos.\n",
    "\t* Adquisicion de datos.\n",
    "\t* Limpieza de datos.\n",
    "3. Exploracion de los datos\n",
    "\t* Construccion de intuicion al respecto.\n",
    "\t* Encontrar patrones.\n",
    "4. Una vez familiarizado con los datos, se querra dibujar algunos \n",
    "(Conclusiones al respecto o tal vez hacer algunas predicciones)\n",
    "\t* Requiere estadistica o aprendizaje automatico.\n",
    "\n",
    "5. Comunicar hallazgos a otras personas\n",
    "\t* Publicacion de blog.\n",
    "\t* Un articulo.\n",
    "\t* Un correo electronico.\n",
    "\t* Presentacion Power Point.\n",
    "\t* Conversacion.\n",
    "\t(La visualizacion de datos es una tecnica comun que casi siempre es util)\n",
    "    \n",
    "_Este proceso en realidad no sigue una linea recta, en especial la fase 2 y 3\n",
    "Porque realmente no se pueden limpiar ningun problema con los datos y si se avanza \n",
    "se encontraran con mas problemas y toque volver a disputar y limpieza de datos.\n",
    "Tambien puede pasar constantemente volver a revisar la pregunta y refinarla.\n",
    "Por otro lado se pueden tener primero los datos y luego pensar en algunas preguntas\n",
    "que se pueden responder con los datos._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSVs in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodecsv\n",
    "\n",
    "def read_csv(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        reader = unicodecsv.DictReader(f)\n",
    "        return list(reader)\n",
    "\n",
    "enrollments = read_csv('enrollments.csv')\n",
    "daily_engagement = read_csv('daily_engagement.csv')\n",
    "project_submissions = read_csv('project_submissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import urllib\n",
    "import csv\n",
    "import unicodecsv \n",
    "from io import StringIO\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/MAXICAPO1999/Udacity/master/daily_engagement.csv'\n",
    "respuesta = urllib.request.urlopen(url)\n",
    "f = StringIO(bytearray(respuesta.read()).decode())\n",
    "archivo = csv.reader(f)\n",
    "\n",
    "for filas in archivo:\n",
    "    print(filas)\n",
    "import unicodecsv\n",
    "import urllib\n",
    "import csv\n",
    "from io import StringIO\n",
    "import codecs\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def read_csv(filename):\n",
    "        reader = unicodecsv.DictReader(filename)\n",
    "        return list(reader)\n",
    "\n",
    "response = urlopen('https://raw.githubusercontent.com/MAXICAPO1999/Udacity/master/daily_engagement.csv')\n",
    "read = csv.reader(codecs.iterdecode(response, 'utf-8'))\n",
    "\n",
    "enrollments = read_csv(read)\n",
    "#daily_engagement = read_csv(url)\n",
    "#project_submissions = read_csv(url)\n",
    "\n",
    "print (enrollments[0])\n",
    "#print (daily_engagement[0])\n",
    "#print (project_submissions[0])\n",
    "\n",
    "import unicodecsv\n",
    "\n",
    "def read_csv(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        reader = unicodecsv.DictReader(f)\n",
    "        return list(reader)\n",
    "\n",
    "enrollments = read_csv('enrollments.csv')\n",
    "daily_engagement = read_csv('daily_engagement.csv')\n",
    "project_submissions = read_csv('project_submissions.csv')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('account_key', '448'), ('status', 'canceled'), ('join_date', '2014-11-10'), ('cancel_date', '2015-01-14'), ('days_to_cancel', '65'), ('is_udacity', 'True'), ('is_canceled', 'True')])\n",
      "---------------------------------------------------------------------------\n",
      "OrderedDict([('acct', '0'), ('utc_date', '2015-01-09'), ('num_courses_visited', '1.0'), ('total_minutes_visited', '11.6793745'), ('lessons_completed', '0.0'), ('projects_completed', '0.0')])\n",
      "---------------------------------------------------------------------------\n",
      "OrderedDict([('creation_date', '2015-01-14'), ('completion_date', '2015-01-16'), ('assigned_rating', 'UNGRADED'), ('account_key', '256'), ('lesson_key', '3176718735'), ('processing_state', 'EVALUATED')])\n"
     ]
    }
   ],
   "source": [
    "print (enrollments[0])\n",
    "print (\"---------------------------------------------------------------------------\")\n",
    "print (daily_engagement[0])\n",
    "print (\"---------------------------------------------------------------------------\")\n",
    "print (project_submissions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enrollments)\n",
    "\n",
    "unique_enrolled_students = set()\n",
    "for enrollment in enrollments:\n",
    "    unique_enrolled_students.add(enrollment['account_key'])\n",
    "len(unique_enrolled_students)\n",
    "\n",
    "len(daily_engagement)\n",
    "\n",
    "unique_engagement_students = set()\n",
    "for engagement_record in daily_engagement:\n",
    "    unique_engagement_students.add(engagement_record['acct'])\n",
    "len(unique_engagement_students)\n",
    "\n",
    "len(project_submissions)\n",
    "\n",
    "unique_project_submitters = set()\n",
    "for submission in project_submissions:\n",
    "    unique_project_submitters.add(submission['account_key'])\n",
    "len(unique_project_submitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for engagement_record in daily_engagement:\n",
    "    engagement_record['account_key'] = engagement_record['acct']\n",
    "    del[engagement_record['acct']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing engagement records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('account_key', '1219'), ('status', 'canceled'), ('join_date', '2014-11-12'), ('cancel_date', '2014-11-12'), ('days_to_cancel', '0'), ('is_udacity', 'False'), ('is_canceled', 'True')])\n"
     ]
    }
   ],
   "source": [
    "for enrollment in enrollments:\n",
    "    student = enrollment['account_key']\n",
    "    if student not in unique_engagement_students:\n",
    "        print (enrollment)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for more problem records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('account_key', '1304'), ('status', 'canceled'), ('join_date', '2015-01-10'), ('cancel_date', '2015-03-10'), ('days_to_cancel', '59'), ('is_udacity', 'True'), ('is_canceled', 'True')])\n",
      "OrderedDict([('account_key', '1304'), ('status', 'canceled'), ('join_date', '2015-03-10'), ('cancel_date', '2015-06-17'), ('days_to_cancel', '99'), ('is_udacity', 'True'), ('is_canceled', 'True')])\n",
      "OrderedDict([('account_key', '1101'), ('status', 'current'), ('join_date', '2015-02-25'), ('cancel_date', ''), ('days_to_cancel', ''), ('is_udacity', 'True'), ('is_canceled', 'False')])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_problem_students = 0\n",
    "for enrollment in enrollments:\n",
    "    student = enrollment['account_key']\n",
    "    if (student not in unique_engagement_students and \n",
    "            enrollment['join_date'] != enrollment['cancel_date']):\n",
    "        print (enrollment)\n",
    "        num_problem_students += 1\n",
    "\n",
    "num_problem_students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining the Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1302"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udacity_test_accounts = set()\n",
    "for enrollment in enrollments:\n",
    "    if enrollment['is_udacity']:\n",
    "        udacity_test_accounts.add(enrollment['account_key'])\n",
    "len(udacity_test_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_udacity_accounts(data):\n",
    "    non_udacity_data = []\n",
    "    for data_point in data:\n",
    "        if data_point['account_key'] not in udacity_test_accounts:\n",
    "            non_udacity_data.append(data_point)\n",
    "    return non_udacity_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "non_udacity_enrollments = remove_udacity_accounts(enrollments)\n",
    "non_udacity_engagement = remove_udacity_accounts(daily_engagement)\n",
    "non_udacity_submissions = remove_udacity_accounts(project_submissions)\n",
    "\n",
    "print (len(non_udacity_enrollments))\n",
    "print (len(non_udacity_engagement))\n",
    "print (len(non_udacity_submissions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paid_students = {}\n",
    "for enrollment in non_udacity_enrollments:\n",
    "    if (not enrollment['is_canceled'] or\n",
    "            enrollment['days_to_cancel'] > 7):\n",
    "        account_key = enrollment['account_key']\n",
    "        enrollment_date = enrollment['join_date']\n",
    "        if (account_key not in paid_students or\n",
    "                enrollment_date > paid_students[account_key]):\n",
    "            paid_students[account_key] = enrollment_date\n",
    "len(paid_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data from First Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def within_one_week(join_date, engagement_date):\n",
    "    time_delta = engagement_date - join_date\n",
    "    return time_delta.days < 7\n",
    "\n",
    "def remove_free_trial_cancels(data):\n",
    "    new_data = []\n",
    "    for data_point in data:\n",
    "        if data_point['account_key'] in paid_students:\n",
    "            new_data.append(data_point)\n",
    "    return new_data\n",
    "\n",
    "paid_enrollments = remove_free_trial_cancels(non_udacity_enrollments)\n",
    "paid_engagement = remove_free_trial_cancels(non_udacity_engagement)\n",
    "paid_submissions = remove_free_trial_cancels(non_udacity_submissions)\n",
    "\n",
    "print (len(paid_enrollments))\n",
    "print (len(paid_engagement))\n",
    "print (len(paid_submissions))\n",
    "\n",
    "paid_engagement_in_first_week = []\n",
    "for engagement_record in paid_engagement:\n",
    "    account_key = engagement_record['account_key']\n",
    "    join_date = paid_students[account_key]\n",
    "    engagement_record_date = engagement_record['utc_date']\n",
    "\n",
    "    if within_one_week(join_date, engagement_record_date):\n",
    "         paid_engagement_in_first_week.append(engagement_record)\n",
    "\n",
    "len(paid_engagement_in_first_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Data Analysis Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*_Se puede observar que falla por el hecho de que este curso fue desarrollado en version 2.0 python, sin embargo python 2 dejo de tener soporte dado que los desarrolladores tiene que avanzar en nuevos desarrollos del lenguaje_*\n",
    "\n",
    "[URL Implementation](https://docs.python.org/3/library/stdtypes.html#dict-views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'dict_values' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-453fb60fc03c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Maximum:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mdescribe_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_minutes_by_account\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-453fb60fc03c>\u001b[0m in \u001b[0;36mdescribe_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdescribe_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Mean:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Standard deviation:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Minimum:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   3255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3256\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[1;32m-> 3257\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   3258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'dict_values' and 'int'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def group_data(data, key_name):\n",
    "    grouped_data = defaultdict(list)\n",
    "    for data_point in data:\n",
    "        key = data_point[key_name]\n",
    "        grouped_data[key].append(data_point)\n",
    "    return grouped_data\n",
    "\n",
    "engagement_by_account = group_data(paid_engagement_in_first_week,\n",
    "                                   'account_key')\n",
    "\n",
    "def sum_grouped_items(grouped_data, field_name):\n",
    "    summed_data = {}\n",
    "    for key, data_points in grouped_data.items():\n",
    "        total = 0\n",
    "        for data_point in data_points:\n",
    "            total += data_point[field_name]\n",
    "        summed_data[key] = total\n",
    "    return summed_data\n",
    "\n",
    "total_minutes_by_account = sum_grouped_items(engagement_by_account,\n",
    "                                             'total_minutes_visited')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def describe_data(data):\n",
    "    print ('Mean:', np.mean(data))\n",
    "    print ('Standard deviation:', np.std(data))\n",
    "    print ('Minimum:', np.min(data))\n",
    "    print ('Maximum:', np.max(data))\n",
    "\n",
    "describe_data(total_minutes_by_account.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La mayoria de los datos todavia estan incluidos, que es lo que se esperaba.\n",
    "(Es mejor crear nuevas variables de los datos actualizados, en caso de que se requiera\n",
    "volver a ver los datos originales).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparacion entre NumPy y Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. NumPy: Es el equivalente de Matlab en entorno de python, Imagenes, Matematicas, Matrices...\n",
    "    Mas informacion aqui [NumPy.org](NumPy.org)\n",
    "2. Pandas: Paquete mas versatil (lib que facilita poder leer un **DATA-SET**, 'Conjunto de datos' en algun formato que sea util).\n",
    "           python utiliza un formato clasico y estandar llamado **DATA_FRAME**, esta libreria tambien nos sirve para \n",
    "           calcular desviaciones, varianzas, concatenar, rellenar, subconjuntos, combinar...        \n",
    "           Mas informacion aqui [Organizacion - Comunidad](PyData.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Python es un lenguaje de programacion bastantemente enfocado hacia la estadistica y analisis de los datos, dado que usar un **for** en este lenguaje es demasiadamente ineficiente, por lo que ya existen algoritmos (librerias) que se encargan de buscar de forma eficiente en un gran volumen de datos, por otro lado esta ciencia de los datos no tiene una especie de orden o proceso exacto ya que la obtencion de los datos puede varias y es lo mas comun, es un proceso reiterativo y siempre analizando el contexto aunque el mismo pueda cambiar._\n",
    "\n",
    "* Mas que una ciencia es un arte.\n",
    "\n",
    "* Los datos se pueden analizar con dos puntos de vista diferentes.\n",
    "    * Analisis retrospectivo: Este enfoque analiza la historia a describir algunos **inside**,\n",
    "    lo que mas ayuda es a encontrar fallos.\n",
    "    \n",
    "    * Analisis Predictivo: Nos da una vision al dato, predicir el futuro.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-8e2f47fd1deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubmission\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproject_submissions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'completion_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'completion_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'creation_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'creation_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menrollments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'parse_date' is not defined"
     ]
    }
   ],
   "source": [
    "'''for submission in project_submissions:\n",
    "    submission['completion_date'] = parse_date(submission['completion_date'])\n",
    "    submission['creation_date'] = parse_date(submission['creation_date'])\n",
    "\n",
    "len(enrollments)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
